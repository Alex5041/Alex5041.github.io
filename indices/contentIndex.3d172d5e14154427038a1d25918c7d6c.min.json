{"/":{"title":"WaterStop","content":"\nHello! My name is Alex and I'm a programmer. On [itch.io](https://waterstop.itch.io/) I put\nmy playable projects\n\n# Site content \n\n[ReGIna WIP](regina/regina) - documentation about WIP programming language\n\n[100 days](100-days/100-writing-days) of English essays\n\n[other notes](notes)\n","lastmodified":"2022-07-02T22:48:33.246077445Z","tags":null},"/100-days/100-writing-days":{"title":"100 writing days","content":"\nPreviously I did 100 reading days, but looking back, I think It was mostly about\nachieving consistency rather than improving pronunciation. Additionally, it is much easier than\nwriting, because it's consuming, not creating. This time, I'll try to write every day for 100 days,\nfollowing these rules:\n\n1. Write on paper and scan it with Google Lens. Handwriting is more beneficial for improving\n   writing ability.\n2. Write at least 10 sentences and 300 words.\n\nLinks to all articles:\n\n28 June: [Heap and Stack](100-days/heap-and-stack)\n\n29 June: [How languages are run?](100-days/transpilers-compilers-interpreters)\n\n30 June: [Abstract syntax tree](100-days/ast)\n\n1 July: [C#: boxing, unboxing and equality operator](100-days/boxing-and-equality-cs)\n\n2 July: [Introduction to grammars](100-days/introduction-to-grammars)","lastmodified":"2022-07-02T22:48:33.246077445Z","tags":null},"/100-days/ast":{"title":"Abstract Syntax free","content":"\nAbstract Syntax Tree (AST) is key concept in program evaluation. It is a tree with\ntokens as its nodes. Tree is a better structure than sequence. Here is why:\n\n1. Operator precedence.\n2. Hierarchy\n\n### Operator precedence\n\nConsider a following expression : $5 + 7 \\cdot 2 + 3$. It is obvious to us humans which arithmetic\noperator. we should calculate first. But it is not that simple for a machine.\nHence, we introduce a tree structure:\n\n{{\u003c svg \"static/ast_arithmetic.svg\" \u003e}}\n\nNow we need to recursively evaluate each child before calculating the result of the overall\nexpression.\n\n### Hierarchy\n\nLet's look at the following python code:\n\n```python\ndef some_method():\n    return 1\n\n\nclass SomeClass:\n    field = 1\n    other = \"other\"\n\n    def class_method(self):\n        return self\n\n    def other_one(self):\n        return \"not classMethod\"\n```\n\nHere is a sketch of AST representation:\n\n```\nsome_method:\n    type: function\n    children:\n        params: ...\n        body: ...\nSomeClass:\n    type: class\n    children:\n        field:\n            type: variable\n            children:\n                value: ...\n        other:\n            type: variable\n            children:\n                value: ...\n        class_method:\n            type: function\n            children:\n                params: ...\n                body: ...\n         other_one:\n            type: function\n            children:\n                params: ...\n                body: ...\n        \n```\n\nNotice how all the functions of class are on the same level. We could even add `fields` and\n`functions` and `classes` nodes to separate statements of different kinds:\n\n```\nfunctions:\n    some_method:\n        ...\nclasses:\n    SomeClass:\n        type: class\n        children:\n            fields:\n                field:\n                    ...\n                other:\n                   ...\n            functions:\n                class_method:\n                    ...\n                 other_one:\n                    ...\n```\n\nThis hierarchical structure is predictable and manageable.\n\n### Node structure\n\nAST trees do not have a commonly accepted structure. It's content varies depending on\nusage. But I found some general structure of AST node. Nodes usually include.\n\n* node type (declaration of class, method, variable, infix operator, block etc)\n* node value: e.g. name of a particular identifier\n* children: nodes that a re children of the current one\n* meta information: position in the initial file, path to initial file...\n\n# Creating AST\n\nA pipeline consists of two steps:\n\n`Code (text) -\u003e Tokens -\u003e AST`\n\nTo create tokens from code, a tokenizer (aka Lexer) is used. Usually it's pretty straightforward:\nread until next whitespace, identify obtained token.\n\nTo create AST from tokens, we need a parser. I won't go into much detail here, because parsers are\ncomplicated enough for a separate post. Classification of parsers:\n\n* Top-down parser. This parser creates a tree from root to leaves.\n    * Back-tracking. The one which looks some tokens behind to define a position of current token\n      in a\n      tree.\n    * Non back-tracking. These parsers do not use previous tokens.\n        * LL$(k)$ parser. Parser from left to right, looking $k$ tokens ahead. Basically is a\n          pushdown automata. Note: a subset of languages that can be parsed with LL$(k)$ parser is\n          called LL$(k)$ languages. These terms parsed go beyond ASTs.\n* Bottom-up parser. Unlike top-down, creates tree starting from leaves and finishing at root.\n","lastmodified":"2022-07-02T22:48:33.246077445Z","tags":null},"/100-days/boxing-and-equality-cs":{"title":"C#: Boxing, unboxing and equality operator","content":"\n# Boxing / unboxing\n\nBoxing/unboxing has to do with reference and value types. Value types store their values on\nstack (usually primitives). Reference types store value in heap and reference to that value on\nstack.\n\nBoxing is process of converting value type to reference type, unboxing is\nthe opposite. These procedures are computationally expensive, because:\n\n* to box a value, a new object should be created.\n* to unbox a value, it should be cast to a particular type, which is time-consuming (albeit to a\n  lesser extent than boxing). To avoid boxing, one\n  should use generics.\n\n# Equality\n\nThere are two types of equality: reference and value.\nReference equality is applicable only to reference types.\nIt checks that two objects point to the same value in heap.\nValue equality checks that two variables contain the same value.\n\n*Note: `==` operator will call `ReferenceEquals` for reference types and is not applicable for two\nvariables of different type.*\n\n### Examples\n\n```C#\n  int a = 3;\n  object pA = a; // implicit boxing\n  object explicitPA = (object)a; // explicit boxing\n  int b = (int)pA; // explicit unboxing - cast an object to type (the only possible way)\n  int implicitUnboxing = pA; // Error: Cannot implicitly convert type 'object' to 'int'\n\n  Console.WriteLine(ReferenceEquals(a, pA)); // False\n  Console.WriteLine(Equals(a, pA)); // True\n  Console.WriteLine(ReferenceEquals((object)a, pA)); // False\n  Console.WriteLine(a == b); // True, calls Equals()\n  Console.WriteLine((object)a == (object)b); // False, calls ReferenceEquals()\n  Console.WriteLine(a == pA); // Error: Operator '==' cannot be applied to operands if type 'int' and 'object'\n```","lastmodified":"2022-07-02T22:48:33.246077445Z","tags":null},"/100-days/cpp-pointers":{"title":"C++ Memory model","content":"\nMemory is a two column table. First row contains **addresses**, second row contains **values**.\n\n```C++\nint x = 4;\n```\n\nWhen variable is assigned, an empty memory row cell is chosen. Variable's value is written to\nsecond column of the row.\n|Address|Value|Assigned variable (not part of a memory, just a showcase example)|\n|------|------| ---- |\n|0x1000| 4| x|\n|0x1004| 0x1000|pX|\n|0x1008|4|y|\n\n# Pointer\n\n```C++\nint* pX = \u0026x;\n```\n\nVariable declaration with a `*` after type states that it is a pointer to that type. In this\ncase, **pX is an integer pointer**. Instead of storing value, pointer variable store memory address\nin their value column (second column of a memory row).\n\n`\u0026` is for extracting address from a variable. `\u0026x` means **address of variable named x**\n\n# Dereference\n\n```C++\nint y = *pX;\n```\n\nVariable with a preceding asterisk (`*`) referred to as a **dereference**. When used before a\npointer variable, this expression will return a value in a row, to which such variable points to.","lastmodified":"2022-07-02T22:48:33.246077445Z","tags":null},"/100-days/heap-and-stack":{"title":"Basic memory management","content":"\n*Last fall, I had an interview.\nThey asked me about differences between heap and stack, how\nreferences and variables are stored.\nI was confident that I knew all this stuff.\nApparently, I was wrong.*\n\n# Commonalities\n\nBoth stack and heap use RAM.\n\n# Stack\n\nStack is a LIFO static[^1] storage that contains:\n\n* Local primitive variables\n* References to non-primitive variables\n* Method parameters\n* Sequence of method calls (hence, each thread has its own stack. Also, this is the reason why\n  infinite recursion will result in stack overflow error)\n\nWhen the method finishes its execution, a stack is emptied with one assembly command - moving\nthe pointer to stack head. Therefore, a stack returns to the state before that method's call.\n\n### Primitive variables\n\nLocal primitive variables are stored in stack. Primitive fields of an object instance are stored in\nheap.\n\n# Heap\n\nHeap is a dynamic memory structure that stores non-primitive variables. References (pointers to\nvariable address in the heap) to these variables are in the stack.\n\nUnlike stack, heap is commonly shared between threads. Consequently, one object shouldn't be\nmodified simultaneously from different threads.\n\nOut of memory error is possible for the heap too.\n\n### Garbage collector and C/C++ features\n\nSome languages (Java, C#) handle memory automatically. A component responsible for it is called\ngarbage collector. Fallback of this approach is unexpected runtime slowdowns due to garbage\ncollector managing memory.\n\nOther languages (C/C++) pass this responsibility on to programmer. In C++ every `new` keyword\nshould\nbe followed by `delete` to prevent memory leak. Additionally, it is possible to store object\ninstance on stack in C++, if variable is declared without `new`. Such local variable will\nbe popped from stack after method\nexecution. [A little more about C++ memory model](100-days/cpp-pointers).\n\n### Heap fragmentation\n\nHeap is a single block of memory. When some memory from heap is released, a chunk of unused memory\nis formed. After many iterations heap becomes a bunch of alternating fragments of used and unused\nmemory.\n\nEssentially this is an inefficient memory utilization, because overall there might be $n$\nbytes of free memory, however not all bytes can be allocated. It is possible to allocate no more\nbytes than there are in the biggest consecutive chunk of free memory.\n\n{{\u003c svg \"static/barcode.svg\" \u003e}}\n\n*After some time heap looks like a barcode (white is free memory, black is unused memory)*\n\n[^1]: some languages allow stack reallocation","lastmodified":"2022-07-02T22:48:33.246077445Z","tags":null},"/100-days/introduction-to-grammars":{"title":"Introduction to grammars","content":"\nGrammar defines a set of strings (words), which is called a **language**.\nEssentially grammar is a `Dictionary \u003cString, String\u003e`, where each dictionary entry is a\n**grammar rule**.\n\nOther two important definitions are terminal and non-terminal symbols.\nTerminal is a string that cannot be resolved into something else,\nunlike non-terminal. Consequently, a result of grammar resolve should always be a sequence\nof terminals.\n\nFor terminals a lowercase letter is assigned, for non-terminal a capital one. Also, there is a\nspecial starting non-terminal marked `S`\n(we assume that we start creating words starting with `S`).\n\n### Creating a grammatically correct word\n\nStarting with `S`, on each step we choose a non-terminal symbol and a rule with the same symbol on\nthe left-hand side. Then such non-terminal is replaced with the right-hand side of the rule. Until\nthere is a non-terminal, a process is continued.\n\nConsider a following example of a grammar:\n\n```\ngrammar gA\nS -\u003e a\nS -\u003e aS\n```\n\nTo create a word `aaa`:\n\n1. Have `S`, use `S -\u003e aS`, now have `aS`\n2. Use `S -\u003e aS`, result is `aaS`\n3. Use `S -\u003e a`, end with `aaa`. All non-terminals are removed.\n\nGenerally this grammar describes a language of words, containing any number of `a`s:\n$L(gA) = \\\\{a^n|n\u003e0\\\\}$\n\n### The Chomsky hierarchy\n\nGrammar with a smaller type number contains all grammars with a bigger type number.\n\n#### Context free grammar (type 2)\n\nGrammars with a single non-terminal symbol on the left of each rule are called context free\ngrammars. Because no context is required for replacing a non-terminal.\n\n#### Regular grammar (type 3)\n\nSubset of content free grammars is regular grammars.\nIt puts a restriction on the right-hand side of\nits rules, three types of expressions are allowed:\n\n* empty string\n* single terminal\n* terminal followed by non-terminal.\n\nExample of a regular grammar:\n\n```\ngrammar gR\nS -\u003e aX\nS -\u003e EOW // (end of word)\nX -\u003e bS\n```\n\nThis grammar defines a language $L(gR) = \\\\{(ab)^n|n\\geqslant0\\\\}$\n\nContext free grammar is a pushdown automata, regular grammar is a finite state machine.\n{{\u003c svg \"static/finite_state_regular.svg\" \u003e}}\n\n#### Context-sensitive grammar (type 1)\n\nContext-sensitive grammars allow left-hand side to contain context, which must be similar in the\nright-hand side. Formally speaking, each rule of context-sensitive grammar is:\n$$c_0Ac_1 \\rightarrow c_0bc_1$$ where:\n\n* $c_0,\\\\; c_1$ are sequences of terminals and non-terminals\n  (sequence might be empty),\n* $A$ is a non-terminal\n* $b$ is a non-empty sequence of terminals and non-terminals.\n\n#### Unrestricted grammar (type 0)\n\nUnrestricted grammars are grammars without any restrictions to their rules.\n\n### BNF, EBNF\n\nThere is a special Backus-Naur form and Extended Backus-Naur form (BNF, EBNF) to\ndescribe a context free grammar. This notation is used most commonly. Here is\na [python grammar defined with EBNF and PEG](https://docs.python.org/3/reference/grammar.html). \n","lastmodified":"2022-07-02T22:48:33.246077445Z","tags":null},"/100-days/transpilers-compilers-interpreters":{"title":"How languages are run?","content":"\nPeople in the programing languages field use fancy buzzwords like **translator, transpiler,\ncompiler, interpreter**, **JIT** (just in time) compiler. Let's figure out what they mean. But\nbefore let's create some sort of programming language hierarchy:\n\n1. High level programming language\n2. Assembly language (low-level language that is still programmable by humans)\n3. Machine code (runs on processor, no reason to write it, because it is undecipherable without\n   helper tools and is processor-specific)\n\n### Translator\n\n**Translator** is a general word for transpilers, compilers and interpreters. It's a tool\nconverting one code to another one (low-level or high level).\n\n### Compiler\n\n**Compilers** create machine code before runtime, which they save into binary files. Each\nprocessor[^1] requires a special compiler. Plus, compiler depends on a platform. Say, there is\na compiler for C++ targeted for the Linux OS and a particular processor.\n\nBenefits of compilers are:\n\n1. Run once to create executable files. Afterwards, run execs each time a program is started.\n2. Compilation is a form of program analysis, which will detect errors (called compilation errors)\n   before running a program, with, for instance, heavy calculations (thus, speeding the refactoring\n   process).\n\nBut there is a considerable drawback for a compiled language. Every little change in the program\nrequires recompilation of the whole module.\n\nLanguages that are compiled: C, C++, Haskell, Rust, Go\n\n### Interpreter\n\n**Interpreters**, on the other hand, can stumble upon such error that compiler could remove,\nbecause\nthey translate a program line by line, during runtime. Due to this translation thing going, a\ntranspiler is initially slower than an already compiled code. But there is a catch, when running a\nprogram line by line, there is more information that can be extracted, because interpreter will see\nvariable values that are impossible to analyse statically, before a program is run[^2]. That\nis where JIT compiler comes into play. It finds runtime optimizations and identifies parts of code\nwhich are faster to compile and execute rather than execute line by line (a default way of\ninterpreter).\n\nBriefly, interpreters:\n\n1. Translate code during runtime, line by line\n   (that is why most of the debuggers are interpreters).\n2. Do not create executable files.\n\nInterpreted languages: Python, Perl, Ruby\n\n### Transpiler\n\nIt is a tool that converts source code of one language to source code of the other language.\nUsually referred to as translators between two high level languages. Transpiler is called source to\nsource compiler sometimes.\n\n### Assembler\n\nAlso, there is a less frequently used term. **Assemblers**. Essentially, they are compilers for\nassembly language. Assemblers convert assembly code into machine code before runtime. I think it\nis a part of a compiler (compilation is a two-step process: translate language into assembly\nlanguage, then translate assembly into machine language).\n\n### Is Java compiled or interpreted?\n\nJava's source code is compiled into a binary byte code.\nThis code runs on JVM (technically not a\nprocessor), that usually is a blazingly fast interpreter (and\noften with a JIT compiler), that maps byte-code commands to processor\ncommands. Java can be considered both compiled and\ninterpreted language, similarly to Kotlin and Scala (JVM languages). Oftentimes though, Java is\nthought to be compiled.\n\nBut I think it is possible to write an interpreter for any compiled language and a compiler for any\ninterpreted language. Therefore, language classification in terms of compiled/interpreted\nlanguages is suggestive, not mandatory.\n\n[^1]: I'm not sure that compiler cannot target multiple processors at once. ISA (Instruction set\narchitecture) of processor is an important thing. Different processors with similar ISAs might be\ntargeted by one compiler.\n\n[^2]: And this cannot be fixed by compiling a program twice: first to run it and find optimizations\nduring runtime, and second to create optimized binary executables. This is because optimizations do\ndepend on the input arguments, which may vary vastly.","lastmodified":"2022-07-02T22:48:33.246077445Z","tags":null},"/Assignment":{"title":"","content":"# Assignment\nLeft side of the assignment before `=` is lvalue, right side is rvalue\n## Lvalue\nThere are 4 types of possible lvalues\n### Variable\n\n### Property\nSimilar to variables, however their scope is class or primitive.\n### Indexing\nChanging array's  element is possible with `arr[i] = ...`\n### Reference","lastmodified":"2022-07-02T22:48:33.246077445Z","tags":null},"/notes/eyes":{"title":"Eye focus and main eye","content":"On sketches that illustrate eye focus, it is shown that humans, when looking straight ahead, focus their vision at a point between their eyes. I came to the conclusion that it is not true, and we focus similarly to the picture on the right.\n\nI have a small experimental proof for it. Look in the mirror. What point are you looking at most of the time? For me, it is the right eye. It is the 'main' eye. If you are looking at your eye too, try switching focus to a different eye and keep it there for some time. It might feel weird, and I think that's because you are switching your main eye. If you got acquainted with that feeling, try looking around with a switched main eye. It certainly feels as if you are focusing similarly to the right picture.\n\n{{\u003c svg \"static/eyes.svg\" \u003e}}   ","lastmodified":"2022-07-02T22:48:33.246077445Z","tags":null},"/regina/dynamic-instantiation":{"title":"","content":"# Dynamic instantiation\n\nClasses can have references to other classes inside them as\nproperties. These property-classes are evaluated dynamically. Take a look at this example:\n\n```kotlin\nclass Node export rect {\n    // export = false - can deny export\n    iter = if (parent) parent.iter + 1 else 0\n\n    childNode = if (iter == 5) Nothing() else Node()\n\n    position = if (childNode is Node) \\\n    Position(childNode.position.x + 1, childNode.position.y) \\\n    else Position(0, 0)\n}\n\nfun main() {\n    Node()\n}\n```\n\nThis will create following svg:\n\n```svg\n\n\u003csvg\u003e\n    \u003crect x=\"4\" y=\"0\"/\u003e\n    \u003crect x=\"3\" y=\"0\"/\u003e\n    \u003crect x=\"2\" y=\"0\"/\u003e\n    \u003crect x=\"1\" y=\"0\"/\u003e\n    \u003crect x=\"0\" y=\"0\"/\u003e\n\u003c/svg\u003e\n```\n\nFirst algorithm creates empty Node() (we'll call it *Node0*) from main(). Then, starting from top to bottom:\n\n1. algorithm assigns **iter** of *Node0* to 0 because parent returns 0 as an equivalent of null.\n2. After that, **childNode** is assigned a new Node (*Node1*).\n3. **position** cannot be assigned because **childNode.position** is not yet assigned. Algorithm goes to\n   childNode.position, that is *Node1*.position and tries to assign it. However, childNode is required, so we go to *\n   Node1*.childNode, which needs iter.\n\n*It's not important to consider while assigning values, but it shows why there cannot be any cyclic dependencies for\nproperties*.\n\n## Implied decision\n\nAlso, it is the reason why class functions are impossible. Imagine this case:\n\n```kotlin\nclass FunctionOveruse {\n    prop = make()\n\n    fun make() {\n        FunctionOveruse()\n        return prop\n    }\n}\n```\n\nBoth lines in ```make()``` will execute forever.\n\nTo make functions as expressive as possible, it is important to allow class instantiating inside them. If\n\nWe either make internal class functions (which is purely decompositional thing) or make instantiating inside functions\npossible (and ```fun main()``` as an entry point)","lastmodified":"2022-07-02T22:48:33.246077445Z","tags":null},"/regina/regina":{"title":"ReGIna","content":"\nis a [dynamically typed](notes/typization.md) language with [syntax](regina/syntax) similar to Kotlin and Python.\n\n## Core idea\n\nDifference between other languages and ReGIna is [dynamic instantiation](regina/dynamic-instantiation). In\nshort, properties in classes will be assigned only after their dependencies are assigned, allowing recursive properties\nof same class `A` inside class `A`.\n[plant](generators/plant.json)\n\n## Advantages\n\n* **Can be embedded into web**. Regina is written in Kotlin and compiled into Javascript.\n* **Rapid generator development**. Look at [examples](#Examples) to see what can be done and how much code is required.\n* **Customizable export**.\n\n## Drawbacks\n\n* **It's slow**. It's definitely slower than Python. Yet it's designed to be fast and concise in creating generators.\n    * **There is no community**. At least not yet. Mail me at kononal@gmail.com if you created something about Regina.\n\n## Examples\n","lastmodified":"2022-07-02T22:48:33.246077445Z","tags":null},"/regina/syntax":{"title":"Syntax","content":"\nReGIna's syntax is an amalgamation of kotlin and python.\n\n## Declarations\n```python\nfrom typing import Iterator\n\n# This is an example\nclass Math:\n    @staticmethod\n    def fib(n: int) -\u003e Iterator[int]:\n        \"\"\" Fibonacci series up to n \"\"\"\n        a, b = 0, 1\n        while a \u003c n:\n            yield a\n            a, b = b, a + b\n\nresult = sum(Math.fib(42))\nprint(\"The answer is {}\".format(result))\n```\n### Class\n\nClass declaration should satisfy following format:\n\n```kotlin \nclass ClassName : SuperClassName export circle {\n    ...\n}\n```\n\nwhere `: SuperClassName` and `export ...` are optional.\n\n### Object\n\n```kotlin\nobject ObjectName export circle {\n    ...\n}\n```\n\nSimilar to type, although it cannot be inherited.\n\n### Function\n\n```kotlin\nfun functionName(arg0, arg1, ...) {\n    ...\n}\n```\n\n### Property/variable assignment\n\n```kotlin\nvariableName = ...\nclassName.PropertyName = ...\n```\n\nVariables and properties are dynamic, meaning they are type independent. `a` can be String and in the next line it can\nbe Int or class instance.\n\n## References\n\nReferences are expressions of form `a.b.c`. They serve 3 purposes:\n\n1. accessing class/object properties\n2. accessing primitive/class/object and functions\n3. specifying package declarations\n4. reducing expressions\n\n### 1. Accessing properties\n\n\n# Code conventions\n\nCamel case is used.\n\nNames of [class](Syntax.md/###Class), [object](Syntax.md/###Object) start with capital.\n\nVariables, functions start with lowercase letter.","lastmodified":"2022-07-02T22:48:33.246077445Z","tags":null},"/regina/typization":{"title":"","content":"Dynamically typed languages check variable type during runtime, meaning it is more **error-prone**.On the contrary,\nstatically typed languages check variable type during compilation.\n\nOften dynamically typed languages can reassign the same variable with a different type. Also, variable declaration and\nassignment are similar for dynamic languages.\n\n```Python\n# Python\na = 2\na = \"2\" # not an error\n```\n\nOne of the clues of static typing is in variable declaration:\nusually variables have a type before a name in declaration:\n\n```C\n // C\n int a = 2;\n a = 3;\n```\n\nHowever, it is not always the case:\n\n```Kotlin\n// Kotlin\nval a = 2\n```\n\nIn Kotlin variable declaration prefix determines its mutability and type is derived from the expression on the right.\n","lastmodified":"2022-07-02T22:48:33.246077445Z","tags":null},"/regina/why":{"title":"","content":"# Why I created a programming language\n\nTLDR: I didn't think about making a library for dynamic instantiation. I should've made a library - that is an optimal path.\n\n## Birth of 'generator or generators'\n\nI liked creating visual generators. But I didn't like spending 2 weeks to flesh out an idea and to implement unuseful\ntools like deployment to web or geometry functions.\n\n*Looking back, I realise that I wasted much time due to switching between tools: for plant generator I used C# and .NET,\nfor House generator I used Godot and for map generator Kotlin with KorGE (there I spend much time figuring out how to\nuse KorGE and writing my own geometry function).*\n\nI needed a tool to create generators. And I started thinking about it. On this stage, there was no intention on creating\na language, all the more so, I was unqualified at that time. I unofficially called this tool the 'generator of\ngenerators'.\n\n## Generator stages\nI had these project specifications (from most to least priority):\n1. It should be possible to create generators of any complexity\n2. It should be concise\n3. Non-programmers should be able to use it\n### Web tool\n\nGeometry primitives:\n\n* Segment\n* Rectangle\n* Polygon/polyline (smooth)\n* Ellipse\n* Arc (circle)\n*\n\nThree types of containers:\n\n1. Variant\n2. Recursive\n3. Container\n\n![Image](images/firstdesign.jpg)\n\n### Early stages of language development\n\n### Upgrading language","lastmodified":"2022-07-02T22:48:33.246077445Z","tags":null}}